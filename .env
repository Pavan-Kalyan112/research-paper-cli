# .env
LLM_PROVIDER=ollama
LLM_MODEL_NAME=mistral
LLM_CHAT_URL=http://localhost:11434/api/chat
USE_LLM=true
LLM_DEBUG=true
DEBUG=false
export POETRY_PYPI_TOKEN_TESTPYPI=your-token-here
